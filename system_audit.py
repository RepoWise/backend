"""
COMPREHENSIVE SYSTEM ROBUSTNESS AUDIT
Tests all aspects of the Agentic RAG system
"""
import asyncio
import json
from app.rag.rag_engine import RAGEngine
from app.agents.intent_router import IntentRouter
from app.agents.orchestrator import AgenticOrchestrator
from app.services.graph_loader import get_graph_loader
from app.models.llm_client import LLMClient
from loguru import logger

logger.remove()  # Clean output

print("=" * 100)
print(" " * 30 + "OSSPREY SYSTEM AUDIT")
print("=" * 100)

# ============================================================================
# TEST 1: VECTOR STORE INDEXING STATUS
# ============================================================================
print("\n" + "=" * 100)
print("TEST 1: VECTOR STORE & DOCUMENT INDEXING")
print("=" * 100)

rag = RAGEngine()

# Get all indexed projects
all_docs = rag.vector_store.get(include=["metadatas"])

if all_docs and all_docs.get("metadatas"):
    # Analyze by project
    projects = {}
    file_types_by_project = {}

    for metadata in all_docs["metadatas"]:
        pid = metadata.get("project_id", "unknown")
        ftype = metadata.get("file_type", "unknown")

        projects[pid] = projects.get(pid, 0) + 1

        if pid not in file_types_by_project:
            file_types_by_project[pid] = {}
        file_types_by_project[pid][ftype] = file_types_by_project[pid].get(ftype, 0) + 1

    print(f"\n‚úÖ Total Indexed Documents: {len(all_docs['metadatas'])}")
    print(f"‚úÖ Projects Indexed: {len(projects)}")

    print("\nüìä Document Distribution:")
    for pid, count in sorted(projects.items(), key=lambda x: x[1], reverse=True):
        print(f"\n  Project: {pid}")
        print(f"    Total Chunks: {count}")
        print(f"    File Types:")
        for ftype, fcount in sorted(file_types_by_project[pid].items()):
            print(f"      - {ftype}: {fcount} chunks")
else:
    print("‚ùå NO DOCUMENTS INDEXED!")

# Check BM25 indices
print(f"\nüìã BM25 Indices:")
for project_id in rag.bm25_indices.keys():
    doc_count = len(rag.bm25_indices[project_id].get("documents", []))
    print(f"  - {project_id}: {doc_count} documents")

# ============================================================================
# TEST 2: GRAPH RAG STATUS (Socio-Technical Data)
# ============================================================================
print("\n" + "=" * 100)
print("TEST 2: GRAPH RAG & SOCIO-TECHNICAL DATA")
print("=" * 100)

try:
    graph_loader = get_graph_loader()

    # Check if CSV data exists
    print(f"\nüìÅ Graph Data Source: {graph_loader.csv_path}")

    has_data = hasattr(graph_loader, 'df') and graph_loader.df is not None
    print(f"‚úÖ Data Loaded: {has_data}")

    if has_data and len(graph_loader.df) > 0:
        print(f"‚úÖ Total Records: {len(graph_loader.df)}")
        print(f"‚úÖ Columns: {list(graph_loader.df.columns)[:10]}...")

        # Check graphs
        if graph_loader.developer_graph:
            dev_count = graph_loader.developer_graph.number_of_nodes()
            collab_count = graph_loader.developer_graph.number_of_edges()
            print(f"\nü§ù Developer Collaboration Graph:")
            print(f"   - Developers: {dev_count}")
            print(f"   - Collaborations: {collab_count}")

        if graph_loader.file_graph:
            file_count = graph_loader.file_graph.number_of_nodes()
            coupling_count = graph_loader.file_graph.number_of_edges()
            print(f"\nüìÑ File Coupling Graph:")
            print(f"   - Files: {file_count}")
            print(f"   - Couplings: {coupling_count}")
    else:
        print("‚ùå NO GRAPH DATA LOADED!")
        print("‚ö†Ô∏è  Graph RAG is NOT functional - need to run scraper tool")

except Exception as e:
    print(f"‚ùå Graph Loader Error: {e}")

# ============================================================================
# TEST 3: LLM HYPERPARAMETERS
# ============================================================================
print("\n" + "=" * 100)
print("TEST 3: LLM CONFIGURATION & HYPERPARAMETERS")
print("=" * 100)

llm = LLMClient()

print(f"\nü§ñ LLM Configuration:")
print(f"   Model: {llm.model}")
print(f"   API Endpoint: {llm.api_endpoint}")
print(f"   Timeout: 120s (configured in client)")

print(f"\n‚öôÔ∏è  Default Generation Parameters:")
print(f"   Temperature: 0.7 (default)")
print(f"   Top-P: 0.9")
print(f"   Top-K: 40")
print(f"   Max Tokens: 512")

print(f"\nüìù NOTE: These can be overridden per-request")

# ============================================================================
# TEST 4: INTENT ROUTING ACCURACY
# ============================================================================
print("\n" + "=" * 100)
print("TEST 4: INTENT ROUTER ACCURACY")
print("=" * 100)

router = IntentRouter()

test_queries = [
    ("What is the governance model?", "governance"),
    ("How do I contribute code?", "governance"),
    ("Who are the top contributors?", "code_collab"),
    ("Which files are most coupled?", "code_collab"),
    ("Should we adopt this project?", "recommendations"),
    ("What is the project sustainability score?", "sustainability"),
    ("Tell me about Python", "general"),
]

print("\nüéØ Testing Intent Classification:")
correct = 0
total = len(test_queries)

for query, expected_intent in test_queries:
    intent, metadata = router.route_query(query, "test-project")
    actual = intent.value
    is_correct = "‚úÖ" if actual == expected_intent else "‚ùå"
    correct += (1 if actual == expected_intent else 0)

    print(f"\n  {is_correct} Query: '{query[:50]}...'")
    print(f"     Expected: {expected_intent}, Got: {actual}")
    print(f"     Method: {metadata['method']}, Confidence: {metadata['confidence']:.2f}")

accuracy = (correct / total) * 100
print(f"\nüìä Routing Accuracy: {accuracy:.1f}% ({correct}/{total})")

if accuracy < 80:
    print("‚ö†Ô∏è  WARNING: Routing accuracy is below 80%!")

# ============================================================================
# TEST 5: DATA SCOPE - WHAT'S BEING INDEXED?
# ============================================================================
print("\n" + "=" * 100)
print("TEST 5: DATA SCOPE - INDEXED CONTENT TYPES")
print("=" * 100)

print("\nüìö Currently Indexed Content:")

governance_files = ["readme", "license", "contributing", "code_of_conduct", "governance", "security", "maintainers"]
indexed_gov = set()

if all_docs and all_docs.get("metadatas"):
    for metadata in all_docs["metadatas"]:
        ftype = metadata.get("file_type", "").lower()
        if ftype in governance_files:
            indexed_gov.add(ftype)

print(f"\n  ‚úÖ Governance Documents:")
for ftype in governance_files:
    status = "‚úÖ" if ftype in indexed_gov else "‚ùå"
    print(f"     {status} {ftype.upper()}")

print(f"\n  ‚ùå GitHub Issues: NOT INDEXED")
print(f"  ‚ùå Pull Requests: NOT INDEXED")
print(f"  ‚ùå Commit Messages: NOT INDEXED (only in Graph RAG)")
print(f"  ‚ùå Issue Comments: NOT INDEXED")

print(f"\n‚ö†Ô∏è  CRITICAL GAP: System only indexes governance docs, not issues/PRs/commits!")
print(f"   Technical Spec requires: Governance + Issues + Commits + PRs + Comments")

# ============================================================================
# TEST 6: END-TO-END QUERY TEST
# ============================================================================
print("\n" + "=" * 100)
print("TEST 6: END-TO-END AGENTIC QUERY TEST")
print("=" * 100)

async def test_e2e_query():
    orchestrator = AgenticOrchestrator(rag_engine=rag)

    test_query = "Tell me about ResilientDB's Apache Incubation status"
    project_id = "resilientdb-incubator-resilientdb"

    print(f"\nüîç Query: '{test_query}'")
    print(f"üì¶ Project: {project_id}")

    from app.agents.base_agent import AgentState

    state = AgentState(
        query=test_query,
        project_id=project_id,
        messages=[],
        context={},
        current_agent=None,
        response="",
        sources=[],
        metadata={}
    )

    try:
        result = await orchestrator.workflow.ainvoke(state)

        print(f"\n‚úÖ Response Generated:")
        print(f"   Length: {len(result['response'])} chars")
        print(f"   Agent: {result['current_agent']}")
        print(f"   Sources: {len(result['sources'])} documents")

        if result['sources']:
            print(f"\n   üìÑ Source Files:")
            for src in result['sources'][:3]:
                print(f"      - {src.get('file_type')}: {src.get('file_path')}")

        print(f"\n   Preview: {result['response'][:200]}...")

    except Exception as e:
        print(f"‚ùå Error: {e}")

asyncio.run(test_e2e_query())

# ============================================================================
# SUMMARY & RECOMMENDATIONS
# ============================================================================
print("\n" + "=" * 100)
print("AUDIT SUMMARY & RECOMMENDATIONS")
print("=" * 100)

print("\n‚úÖ WORKING COMPONENTS:")
print("   1. Vector Store with governance documents")
print("   2. BM25 + Vector hybrid search")
print("   3. Intent routing system")
print("   4. Graph RAG infrastructure (if CSV data present)")
print("   5. LLM generation with proper hyperparameters")
print("   6. Multi-agent orchestration")

print("\n‚ùå CRITICAL GAPS:")
print("   1. OSS Scraper Tool NOT integrated with add project flow")
print("   2. GitHub Issues/PRs NOT indexed into RAG")
print("   3. Commit messages NOT in RAG (only in Graph)")
print("   4. No automatic scraper execution on project add")
print("   5. Graph RAG only works if CSV data manually provided")

print("\nüîß REQUIRED FIXES:")
print("   1. Integrate scraper tool with /api/projects/add endpoint")
print("   2. Index issues/PRs/commits into vector store RAG")
print("   3. Run scraper automatically when project is added")
print("   4. Expand RAG beyond just governance docs")
print("   5. Add dedicated issue/PR/commit document types")

print("\nüìã TECHNICAL SPEC COMPLIANCE:")
print("   ‚ö†Ô∏è  PARTIAL - Missing issues, PRs, commits in RAG")
print("   ‚úÖ Has: Governance docs, Graph RAG structure, Multi-agent")
print("   ‚ùå Missing: Full socio-technical data in RAG")

print("\n" + "=" * 100)
print("AUDIT COMPLETE")
print("=" * 100)
